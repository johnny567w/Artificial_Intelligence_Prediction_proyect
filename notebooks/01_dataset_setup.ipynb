{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a33e5f6",
   "metadata": {},
   "source": [
    "# Primer notebook -\n",
    "En este primer notebook se definiran conceptos claves para el resto del proyecto, tales como el dataset seleccionado, rutas de las principales carpetas para la comunicacion entre notebooks, tambien el datset que se utilizara necesita generar archivos .json para el tratamiento reducido del dataset, se utilizo de base el dataset coco2017 que puede ser decargo de manera publica mediante el sigueinte link: https://www.kaggle.com/datasets/awsaf49/coco-2017-dataset\n",
    "Para este proyecto se usara ya el dataste descrgado de manera local por ende no se descargara en este proyecto, para probarlo deberas descargar el dataset del link anterior y agregarlo en la carptea data de este proyecto IA-final/data/archive/coco2017\n",
    "## Objetivos\n",
    "1. Verificar la estructura del dataset COCO2017 en: `data\\archive\\coco2017`\n",
    "2. Confirmar que los archivos y carpetas necesarias existen.\n",
    "3. Cargar el archivo de anotaciones (instances_train2017.json / instances_val2017.json).\n",
    "4. Definir 3 clases objetivo (para entrenamiento eficiente en CPU).\n",
    "5. Guardar un `labelmap.json` con las clases seleccionadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b2f56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- Importa librerías estándar usadas en todo el notebook.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef012d46",
   "metadata": {},
   "source": [
    "1. Creacion y validacion de rutas y carpetas escenciales para el proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d4c6aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para que confirmes que los datos mas improtantes se encuentren tras tu descarga se debe confirmar que todos estos archvios existan\n",
      "TRAIN_DIR: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\archive\\coco2017\\train2017\n",
      "VAL_DIR  : C:\\Users\\Johnny\\Desktop\\IA-final\\data\\archive\\coco2017\\val2017\n",
      "ANN_DIR  : C:\\Users\\Johnny\\Desktop\\IA-final\\data\\archive\\coco2017\\annotations\n",
      "TRAIN_ANN: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\archive\\coco2017\\annotations\\instances_train2017.json\n",
      "VAL_ANN  : C:\\Users\\Johnny\\Desktop\\IA-final\\data\\archive\\coco2017\\annotations\\instances_val2017.json\n",
      "PROCESSED_DIR: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\processed\n",
      "Clases seleccionadas: ['person', 'car', 'airplane']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "En esta primera seecion:\n",
    "- Define las rutas del dataset COCO2017 de forma única y centralizada.\n",
    "- Define clases objetivo fijas: person, car, airplane. Se elegirieron estas clases dado que presentan un gran numero de referentes en el datset\n",
    "- Crea la carpeta data/processed si no existe.\n",
    "- Guarda el path absoluto (resolve) para evitar ambigüedades en notebooks.\n",
    "\"\"\"\n",
    "PROJECT_ROOT = Path(\"..\")     \n",
    "\n",
    "COCO_ROOT = PROJECT_ROOT / \"data\" / \"archive\" / \"coco2017\"\n",
    "\n",
    "TRAIN_DIR = (COCO_ROOT / \"train2017\").resolve()\n",
    "VAL_DIR = (COCO_ROOT / \"val2017\").resolve()\n",
    "ANN_DIR = (COCO_ROOT / \"annotations\").resolve()\n",
    "\n",
    "TRAIN_ANN = (ANN_DIR / \"instances_train2017.json\").resolve()\n",
    "VAL_ANN = (ANN_DIR / \"instances_val2017.json\").resolve()\n",
    "\n",
    "PROCESSED_DIR = (PROJECT_ROOT / \"data\" / \"processed\").resolve()\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PROJECT_CONFIG_PATH = (PROCESSED_DIR / \"project_config.json\").resolve()\n",
    "LABELMAP_PATH = (PROCESSED_DIR / \"labelmap.json\").resolve()\n",
    "\n",
    "TARGET_CLASSES = [\"person\", \"car\", \"airplane\"]\n",
    "\n",
    "print(\"Para que confirmes que los datos mas improtantes se encuentren tras tu descarga se debe confirmar que todos estos archvios existan\")\n",
    "print(\"TRAIN_DIR:\", TRAIN_DIR)\n",
    "print(\"VAL_DIR  :\", VAL_DIR)\n",
    "print(\"ANN_DIR  :\", ANN_DIR)\n",
    "print(\"TRAIN_ANN:\", TRAIN_ANN)\n",
    "print(\"VAL_ANN  :\", VAL_ANN)\n",
    "print(\"PROCESSED_DIR:\", PROCESSED_DIR)\n",
    "print(\"Clases seleccionadas:\", TARGET_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d32b4421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: COCO_ROOT: ..\\data\\archive\\coco2017\n",
      "OK: train2017: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\archive\\coco2017\\train2017\n",
      "OK: val2017: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\archive\\coco2017\\val2017\n",
      "OK: annotations: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\archive\\coco2017\\annotations\n",
      "OK: instances_train2017.json: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\archive\\coco2017\\annotations\\instances_train2017.json\n",
      "OK: instances_val2017.json: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\archive\\coco2017\\annotations\\instances_val2017.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Esta celda:\n",
    "Una simple validacion de las carpetas anteriores para evitar \n",
    "conflictos de rutas en un futuro, para evitar problemas las declaramos desde el primer notebok\n",
    "\"\"\"\n",
    "\n",
    "def assert_exists(path: Path, label: str) -> None:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Recurso requerido no encontrado: {label}: {path}\")\n",
    "    print(f\"OK: {label}: {path}\")\n",
    "\n",
    "assert_exists(COCO_ROOT, \"COCO_ROOT\")\n",
    "assert_exists(TRAIN_DIR, \"train2017\")\n",
    "assert_exists(VAL_DIR, \"val2017\")\n",
    "assert_exists(ANN_DIR, \"annotations\")\n",
    "assert_exists(TRAIN_ANN, \"instances_train2017.json\")\n",
    "assert_exists(VAL_ANN, \"instances_val2017.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025d2ccb",
   "metadata": {},
   "source": [
    "2. Descripcion del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e289622f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train JSON cargado\n",
      "Categorias: 80\n",
      "Imagenes  : 118287\n",
      "Anotaciones: 860001\n",
      "TARGET_CLASSES: ['person', 'car', 'airplane']\n",
      "target_cat_ids: [1, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Descripcion del dataset y creacion de json\n",
    "- Carga el JSON de anotaciones de train.El cual es necesario para la optimizacion del dataset\n",
    "- Extrae categorías y crea mapeos id<->name.\n",
    "- Verifica que las clases objetivo existan en COCO.\n",
    "\"\"\"\n",
    "\n",
    "with open(TRAIN_ANN, \"r\", encoding=\"utf-8\") as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "categories = train_data[\"categories\"]\n",
    "images = train_data[\"images\"]\n",
    "annotations = train_data[\"annotations\"]\n",
    "\n",
    "cat_id_to_name = {c[\"id\"]: c[\"name\"] for c in categories}\n",
    "cat_name_to_id = {c[\"name\"]: c[\"id\"] for c in categories}\n",
    "\n",
    "missing = [c for c in TARGET_CLASSES if c not in cat_name_to_id]\n",
    "if missing:\n",
    "    raise ValueError(\n",
    "        \"Estas clases objetivo no existen en COCO categories: \" + \", \".join(missing)\n",
    "    )\n",
    "\n",
    "target_cat_ids = [cat_name_to_id[c] for c in TARGET_CLASSES]\n",
    "\n",
    "print(\"Train JSON cargado\")\n",
    "print(\"Categorias:\", len(categories))\n",
    "print(\"Imagenes  :\", len(images))\n",
    "print(\"Anotaciones:\", len(annotations))\n",
    "print(\"TARGET_CLASSES:\", TARGET_CLASSES)\n",
    "print(\"target_cat_ids:\", target_cat_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "576015d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anotaciones por clase objetivo (train):\n",
      "person: 262465\n",
      "car: 43867\n",
      "airplane: 5135\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "- Cuenta cuántas anotaciones hay en train para cada clase objetivo.\n",
    "- Sirve como sanity check de que hay suficientes datos, cabe aclarar que por tema de recursos solo una fraccion de este dataset fue usado para el entrenamiento\n",
    "\"\"\"\n",
    "\n",
    "counter = Counter()\n",
    "for ann in annotations:\n",
    "    cid = ann[\"category_id\"]\n",
    "    if cid in set(target_cat_ids):\n",
    "        counter[cid] += 1\n",
    "\n",
    "print(\"Anotaciones por clase objetivo (train):\")\n",
    "for cls_name, cid in zip(TARGET_CLASSES, target_cat_ids):\n",
    "    print(f\"{cls_name}: {counter[cid]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b76a16a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\processed\\project_config.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Aqui empezaos a crear codigo reutilizable para el resto de notebooks.\n",
    "- Guarda una configuración única del proyecto con rutas absolutas.\n",
    "- La idea es que todos los notebooks lean este archivo y no vuelvan a definir rutas a mano.\n",
    "\"\"\"\n",
    "\n",
    "project_config = {\n",
    "    \"project_root\": str(PROJECT_ROOT.as_posix()),\n",
    "    \"coco_root\": str(COCO_ROOT.as_posix()),\n",
    "    \"train_dir\": str(TRAIN_DIR.as_posix()),\n",
    "    \"val_dir\": str(VAL_DIR.as_posix()),\n",
    "    \"ann_dir\": str(ANN_DIR.as_posix()),\n",
    "    \"train_ann\": str(TRAIN_ANN.as_posix()),\n",
    "    \"val_ann\": str(VAL_ANN.as_posix()),\n",
    "    \"processed_dir\": str(PROCESSED_DIR.as_posix()),\n",
    "    \"target_classes\": TARGET_CLASSES,\n",
    "}\n",
    "\n",
    "with open(PROJECT_CONFIG_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(project_config, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Guardado:\", PROJECT_CONFIG_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ae202b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\processed\\labelmap.json\n",
      "{'dataset': 'COCO2017', 'target_classes': ['person', 'car', 'airplane'], 'target_category_ids': [1, 3, 5], 'name_to_id': {'person': 1, 'car': 3, 'airplane': 5}, 'id_to_name': {'1': 'person', '3': 'car', '5': 'airplane'}}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "En esta seccion se realiza lo siguiente\n",
    "- Guarda un labelmap mínimo y estable para el proyecto.\n",
    "- Incluye:\n",
    "  - dataset\n",
    "  - target_classes\n",
    "  - name_to_id e id_to_name solo para las clases objetivo\n",
    "  - target_category_ids\n",
    "\"\"\"\n",
    "\n",
    "labelmap = {\n",
    "    \"dataset\": \"COCO2017\",\n",
    "    \"target_classes\": TARGET_CLASSES,\n",
    "    \"target_category_ids\": target_cat_ids,\n",
    "    \"name_to_id\": {name: cat_name_to_id[name] for name in TARGET_CLASSES},\n",
    "    \"id_to_name\": {str(cat_name_to_id[name]): name for name in TARGET_CLASSES},\n",
    "}\n",
    "\n",
    "with open(LABELMAP_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(labelmap, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Guardado:\", LABELMAP_PATH)\n",
    "print(labelmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85d43731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_config.json OK: ../data/archive/coco2017\n",
      "labelmap.json OK: ['person', 'car', 'airplane']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Esta celda:\n",
    "- Relee project_config.json y labelmap.json para asegurar que se guardaron bien.\n",
    "- Esto evita que el notebook ver como si el notebook funciona, pero no guarda nada.\n",
    "\"\"\"\n",
    "\n",
    "with open(PROJECT_CONFIG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg_check = json.load(f)\n",
    "\n",
    "with open(LABELMAP_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    lm_check = json.load(f)\n",
    "\n",
    "print(\"project_config.json OK:\", cfg_check[\"coco_root\"])\n",
    "print(\"labelmap.json OK:\", lm_check[\"target_classes\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
