{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a55b76",
   "metadata": {},
   "source": [
    "# Second Notebook\n",
    "\n",
    "This notebook is primarily focused on generating .json files prior to training. It uses data previously created in Notebook 1. The paths and directories have already been defined, and the same paths will be reused here.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. Read COCO2017 from `data/archive/coco2017`.\n",
    "2. Filter annotations to 3 classes: person, car, airplane.\n",
    "3. Save the reduced JSON files in `data/processed/`. Due to resource and training time constraints, it is not feasible to use the entire dataset:\n",
    "   - coco_person_car_airplane_train.json\n",
    "   - coco_person_car_airplane_val.json\n",
    "4. Save fast index files, which will be consumed in Notebook 03:\n",
    "   - index_train_person_car_airplane.json\n",
    "   - index_val_person_car_airplane.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f9c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- Imports the standard libraries required for the notebook.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbb52b8",
   "metadata": {},
   "source": [
    "1. Loading .json files and validating the project structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1804f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismo contenido visto anteriormente, solo para confirmar las carpetas \n",
      "PROJECT_ROOT: C:\\Users\\Johnny\\Desktop\\IA-final\n",
      "COCO_ROOT: ..\\data\\archive\\coco2017\n",
      "TRAIN_ANN: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\archive\\coco2017\\annotations\\instances_train2017.json\n",
      "VAL_ANN  : C:\\Users\\Johnny\\Desktop\\IA-final\\data\\archive\\coco2017\\annotations\\instances_val2017.json\n",
      "TARGET_CLASSES: ['person', 'car', 'airplane']\n",
      "target_cat_ids: [1, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this section, the notebook loads project_config.json and labelmap.json created in Notebook 01.\n",
    "It also defines absolute paths without depending on the notebook’s current working directory.\n",
    "\"\"\"\n",
    "\n",
    "# Detectar project root desde el marker data/processed/project_config.json\n",
    "def find_project_root(start: Path, max_up: int = 8) -> Path:\n",
    "    cur = start.resolve()\n",
    "    for _ in range(max_up):\n",
    "        if (cur / \"data\" / \"processed\" / \"project_config.json\").exists():\n",
    "            return cur\n",
    "        cur = cur.parent\n",
    "    raise FileNotFoundError(\"No se encontró data/processed/project_config.json. Ejecuta Notebook 01.\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root(Path.cwd())\n",
    "PROCESSED_DIR = (PROJECT_ROOT / \"data\" / \"processed\").resolve()\n",
    "\n",
    "PROJECT_CONFIG_PATH = (PROCESSED_DIR / \"project_config.json\").resolve()\n",
    "LABELMAP_PATH = (PROCESSED_DIR / \"labelmap.json\").resolve()\n",
    "\n",
    "with open(PROJECT_CONFIG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    project_config = json.load(f)\n",
    "\n",
    "with open(LABELMAP_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    labelmap = json.load(f)\n",
    "\n",
    "COCO_ROOT = Path(project_config[\"coco_root\"])\n",
    "TRAIN_DIR = Path(project_config[\"train_dir\"])\n",
    "VAL_DIR = Path(project_config[\"val_dir\"])\n",
    "TRAIN_ANN = Path(project_config[\"train_ann\"])\n",
    "VAL_ANN = Path(project_config[\"val_ann\"])\n",
    "\n",
    "TARGET_CLASSES = project_config[\"target_classes\"]\n",
    "target_cat_ids = labelmap[\"target_category_ids\"]\n",
    "\n",
    "print(\"Mismo contenido visto anteriormente, solo para confirmar las carpetas \")\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"COCO_ROOT:\", COCO_ROOT)\n",
    "print(\"TRAIN_ANN:\", TRAIN_ANN)\n",
    "print(\"VAL_ANN  :\", VAL_ANN)\n",
    "print(\"TARGET_CLASSES:\", TARGET_CLASSES)\n",
    "print(\"target_cat_ids:\", target_cat_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40d7baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: coco_root: ..\\data\\archive\\coco2017\n",
      "OK: train_dir: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\archive\\coco2017\\train2017\n",
      "OK: val_dir: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\archive\\coco2017\\val2017\n",
      "OK: train_ann: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\archive\\coco2017\\annotations\\instances_train2017.json\n",
      "OK: val_ann: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\archive\\coco2017\\annotations\\instances_val2017.json\n",
      "OK: processed_dir: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here, a simple validation of the previously defined directories is performed to prevent future path conflicts.  \n",
    "This is practically the same as in the first notebook and is done purely as a precaution.\n",
    "\"\"\"\n",
    "\n",
    "def assert_exists(path: Path, label: str) -> None:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Recurso requerido no encontrado: {label}: {path}\")\n",
    "    print(f\"OK: {label}: {path}\")\n",
    "\n",
    "assert_exists(COCO_ROOT, \"coco_root\")\n",
    "assert_exists(TRAIN_DIR, \"train_dir\")\n",
    "assert_exists(VAL_DIR, \"val_dir\")\n",
    "assert_exists(TRAIN_ANN, \"train_ann\")\n",
    "assert_exists(VAL_ANN, \"val_ann\")\n",
    "assert_exists(PROCESSED_DIR, \"processed_dir\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daeb7c7",
   "metadata": {},
   "source": [
    "2. Dataset reduction for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b903d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_TRAIN_IMAGES: 3300\n",
      "MAX_VAL_IMAGES  : 500\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell:\n",
    "- Explicitly defines how many images will be used for base training.\n",
    "- These values control the total training time on CPU.\n",
    "- To prevent excessively large training runs, these limits must be enforced.\n",
    "\"\"\"\n",
    "\n",
    "# Recomendado para CPU y para que el proyecto sea usable\n",
    "MAX_TRAIN_IMAGES = 3300\n",
    "MAX_VAL_IMAGES = 500\n",
    "\n",
    "print(\"MAX_TRAIN_IMAGES:\", MAX_TRAIN_IMAGES)\n",
    "print(\"MAX_VAL_IMAGES  :\", MAX_VAL_IMAGES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb68973d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train original:\n",
      " images: 118287\n",
      " annotations: 860001\n",
      "Val original:\n",
      " images: 5000\n",
      " annotations: 36781\n",
      "Stats train filtrado: {'num_images_original': 118287, 'num_annotations_original': 860001, 'num_images_reduced': 69622, 'num_annotations_reduced': 311467}\n",
      "Stats val filtrado  : {'num_images_original': 5000, 'num_annotations_original': 36781, 'num_images_reduced': 2929, 'num_annotations_reduced': 13079}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here we will use the previously created .json files, specifically the train and validation files.\n",
    "Additionally, the original annotation counts will be displayed as a reference.\n",
    "\"\"\"\n",
    "\n",
    "def load_coco_json(path: Path) -> dict:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_coco = load_coco_json(TRAIN_ANN)\n",
    "val_coco = load_coco_json(VAL_ANN)\n",
    "\n",
    "print(\"Train original:\")\n",
    "print(\" images:\", len(train_coco[\"images\"]))\n",
    "print(\" annotations:\", len(train_coco[\"annotations\"]))\n",
    "print(\"Val original:\")\n",
    "print(\" images:\", len(val_coco[\"images\"]))\n",
    "print(\" annotations:\", len(val_coco[\"annotations\"]))\n",
    "\"\"\"\n",
    " Aqui se busca filtrar COCO para conservar solo anotaciones de las clases objetivo,mantiene únicamente imágenes que tengan al menos 1 anotación objetivo.\n",
    "\"\"\"\n",
    "\n",
    "def filter_coco_to_targets(coco: dict, target_cat_ids: list[int]) -> tuple[dict, dict]:\n",
    "    images = coco[\"images\"]\n",
    "    annotations = coco[\"annotations\"]\n",
    "    categories = coco[\"categories\"]\n",
    "\n",
    "    cat_id_set = set(int(x) for x in target_cat_ids)\n",
    "\n",
    "    reduced_categories = [c for c in categories if c[\"id\"] in cat_id_set]\n",
    "    filtered_anns = [a for a in annotations if a[\"category_id\"] in cat_id_set]\n",
    "\n",
    "    img_id_to_anns = defaultdict(list)\n",
    "    for a in filtered_anns:\n",
    "        img_id_to_anns[a[\"image_id\"]].append(a)\n",
    "\n",
    "    reduced_images = [img for img in images if img[\"id\"] in img_id_to_anns]\n",
    "\n",
    "    valid_img_ids = {img[\"id\"] for img in reduced_images}\n",
    "    filtered_anns = [a for a in filtered_anns if a[\"image_id\"] in valid_img_ids]\n",
    "\n",
    "    reduced = {\n",
    "        \"info\": coco.get(\"info\", {}),\n",
    "        \"licenses\": coco.get(\"licenses\", []),\n",
    "        \"images\": reduced_images,\n",
    "        \"annotations\": filtered_anns,\n",
    "        \"categories\": reduced_categories,\n",
    "    }\n",
    "\n",
    "    stats = {\n",
    "        \"num_images_original\": len(images),\n",
    "        \"num_annotations_original\": len(annotations),\n",
    "        \"num_images_reduced\": len(reduced_images),\n",
    "        \"num_annotations_reduced\": len(filtered_anns),\n",
    "    }\n",
    "\n",
    "    return reduced, stats\n",
    "\n",
    "reduced_train, stats_train = filter_coco_to_targets(train_coco, target_cat_ids)\n",
    "reduced_val, stats_val = filter_coco_to_targets(val_coco, target_cat_ids)\n",
    "\n",
    "print(\"Stats train filtrado:\", stats_train)\n",
    "print(\"Stats val filtrado  :\", stats_val)\n",
    "\n",
    "if stats_train[\"num_images_reduced\"] == 0:\n",
    "    raise RuntimeError(\"Train filtrado quedó vacío. Revisa TARGET_CLASSES/labelmap.\")\n",
    "if stats_val[\"num_images_reduced\"] == 0:\n",
    "    raise RuntimeError(\"Val filtrado quedó vacío. Revisa TARGET_CLASSES/labelmap.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae092e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train final:\n",
      " images: 3300\n",
      " annotations: 14546\n",
      "Val final:\n",
      " images: 500\n",
      " annotations: 2218\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell:\n",
    "- Reduces the filtered dataset to CPU-safe sizes.\n",
    "- Updates the annotations so that only those corresponding to the selected images remain.\n",
    "- The JSON saved to disk is genuinely reduced.\n",
    "\"\"\"\n",
    "\n",
    "def trim_coco(coco_reduced: dict, max_images: int) -> dict:\n",
    "    images = coco_reduced[\"images\"]\n",
    "    annotations = coco_reduced[\"annotations\"]\n",
    "\n",
    "    images_trim = images[:max_images]\n",
    "    valid_ids = {img[\"id\"] for img in images_trim}\n",
    "\n",
    "    anns_trim = [a for a in annotations if a[\"image_id\"] in valid_ids]\n",
    "\n",
    "    out = coco_reduced.copy()\n",
    "    out[\"images\"] = images_trim\n",
    "    out[\"annotations\"] = anns_trim\n",
    "    return out\n",
    "\n",
    "reduced_train = trim_coco(reduced_train, MAX_TRAIN_IMAGES)\n",
    "reduced_val = trim_coco(reduced_val, MAX_VAL_IMAGES)\n",
    "\n",
    "print(\"Train final:\")\n",
    "print(\" images:\", len(reduced_train[\"images\"]))\n",
    "print(\" annotations:\", len(reduced_train[\"annotations\"]))\n",
    "\n",
    "print(\"Val final:\")\n",
    "print(\" images:\", len(reduced_val[\"images\"]))\n",
    "print(\" annotations:\", len(reduced_val[\"annotations\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ba322a",
   "metadata": {},
   "source": [
    "3. Saving .json files for training with the reduced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b7a7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\processed\\coco_person_car_airplane_train.json\n",
      "Guardado: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\processed\\coco_person_car_airplane_val.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Once the dataset size to be used has been defined, the reduced .json files are saved in `data/processed`.\n",
    "This helps ensure that they physically exist on disk at the end of the process.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "OUT_TRAIN_JSON = (PROCESSED_DIR / \"coco_person_car_airplane_train.json\").resolve()\n",
    "OUT_VAL_JSON = (PROCESSED_DIR / \"coco_person_car_airplane_val.json\").resolve()\n",
    "\n",
    "with open(OUT_TRAIN_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(reduced_train, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "with open(OUT_VAL_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(reduced_val, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "if not OUT_TRAIN_JSON.exists():\n",
    "    raise FileNotFoundError(f\"No se creó: {OUT_TRAIN_JSON}\")\n",
    "if not OUT_VAL_JSON.exists():\n",
    "    raise FileNotFoundError(f\"No se creó: {OUT_VAL_JSON}\")\n",
    "\n",
    "print(\"Guardado:\", OUT_TRAIN_JSON)\n",
    "print(\"Guardado:\", OUT_VAL_JSON)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83699fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\processed\\index_train_person_car_airplane.json\n",
      "Guardado: C:\\Users\\Johnny\\Desktop\\IA-final\\data\\processed\\index_val_person_car_airplane.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This section:\n",
    "- Builds fast indices for each split:\n",
    "  - List of images with metadata\n",
    "  - Annotations grouped by image_id\n",
    "  - Per-class counts\n",
    "- Saves the indices in `data/processed`.\n",
    "\"\"\"\n",
    "\n",
    "def build_index(coco_reduced: dict, target_cat_ids: list[int]) -> dict:\n",
    "    images = coco_reduced[\"images\"]\n",
    "    annotations = coco_reduced[\"annotations\"]\n",
    "\n",
    "    img_id_to_anns = defaultdict(list)\n",
    "    class_counter = Counter()\n",
    "\n",
    "    for a in annotations:\n",
    "        img_id = a[\"image_id\"]\n",
    "        img_id_to_anns[img_id].append({\n",
    "            \"id\": a[\"id\"],\n",
    "            \"bbox\": a[\"bbox\"],\n",
    "            \"category_id\": a[\"category_id\"],\n",
    "            \"iscrowd\": a.get(\"iscrowd\", 0),\n",
    "            \"area\": a.get(\"area\", None),\n",
    "        })\n",
    "        class_counter[a[\"category_id\"]] += 1\n",
    "\n",
    "    index_images = [{\n",
    "        \"id\": img[\"id\"],\n",
    "        \"file_name\": img[\"file_name\"],\n",
    "        \"width\": img.get(\"width\"),\n",
    "        \"height\": img.get(\"height\"),\n",
    "        \"num_anns\": len(img_id_to_anns.get(img[\"id\"], [])),\n",
    "    } for img in images]\n",
    "\n",
    "    return {\n",
    "        \"target_classes\": TARGET_CLASSES,\n",
    "        \"target_category_ids\": target_cat_ids,\n",
    "        \"num_images\": len(index_images),\n",
    "        \"num_annotations\": len(annotations),\n",
    "        \"class_counts_by_category_id\": {str(k): int(v) for k, v in class_counter.items()},\n",
    "        \"images\": index_images,\n",
    "        \"annotations_by_image_id\": {str(k): v for k, v in img_id_to_anns.items()},\n",
    "    }\n",
    "\n",
    "train_index = build_index(reduced_train, target_cat_ids)\n",
    "val_index = build_index(reduced_val, target_cat_ids)\n",
    "\n",
    "OUT_TRAIN_INDEX = (PROCESSED_DIR / \"index_train_person_car_airplane.json\").resolve()\n",
    "OUT_VAL_INDEX = (PROCESSED_DIR / \"index_val_person_car_airplane.json\").resolve()\n",
    "\n",
    "with open(OUT_TRAIN_INDEX, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(train_index, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "with open(OUT_VAL_INDEX, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(val_index, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Guardado:\", OUT_TRAIN_INDEX)\n",
    "print(\"Guardado:\", OUT_VAL_INDEX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586f6da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificación desde disco:\n",
      "TRAIN images: 3300\n",
      "VAL images  : 500\n",
      "Preprocesamiento finalizado correctamente. Notebook 03 ya puede entrenar en CPU.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "After completing the previous steps, this section ensures that the final JSON saved to disk is reloaded and its counts are verified.\n",
    "\"\"\"\n",
    "\n",
    "with open(OUT_TRAIN_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    train_check = json.load(f)\n",
    "\n",
    "with open(OUT_VAL_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    val_check = json.load(f)\n",
    "\n",
    "print(\"Verificación desde disco:\")\n",
    "print(\"TRAIN images:\", len(train_check[\"images\"]))\n",
    "print(\"VAL images  :\", len(val_check[\"images\"]))\n",
    "\n",
    "if len(train_check[\"images\"]) != MAX_TRAIN_IMAGES:\n",
    "    raise RuntimeError(\n",
    "        \"El TRAIN_JSON guardado no coincide con MAX_TRAIN_IMAGES. \"\n",
    "        \"No continúes con Notebook 03 hasta corregir esto.\"\n",
    "    )\n",
    "\n",
    "if len(val_check[\"images\"]) != MAX_VAL_IMAGES:\n",
    "    raise RuntimeError(\n",
    "        \"El VAL_JSON guardado no coincide con MAX_VAL_IMAGES. \"\n",
    "        \"No continúes con Notebook 03 hasta corregir esto.\"\n",
    "    )\n",
    "\n",
    "print(\"Preprocesamiento finalizado correctamente. Notebook 03 ya puede entrenar en CPU.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
